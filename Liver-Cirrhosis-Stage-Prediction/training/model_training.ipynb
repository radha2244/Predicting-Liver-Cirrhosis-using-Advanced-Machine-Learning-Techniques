{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02c8681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anuup\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\anuup\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\anuup\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         6\n",
      "         1.0       0.18      0.17      0.17        18\n",
      "         2.0       0.47      0.57      0.52        28\n",
      "         3.0       0.62      0.58      0.60        31\n",
      "\n",
      "    accuracy                           0.48        83\n",
      "   macro avg       0.57      0.45      0.49        83\n",
      "weighted avg       0.50      0.48      0.48        83\n",
      "\n",
      " Model and scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: Import Required Libraries ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "# === STEP 2: Load Dataset ===\n",
    "df = pd.read_csv(\"cirrhosis.csv\")\n",
    "\n",
    "# === STEP 3: Drop rows with missing target variable ===\n",
    "df = df.dropna(subset=[\"Stage\"]).copy()\n",
    "\n",
    "# === STEP 4: Encode Categorical Features ===\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"M\": 1, \"F\": 0})\n",
    "df[\"Ascites\"] = df[\"Ascites\"].map({\"Y\": 1, \"N\": 0})\n",
    "df[\"Hepatomegaly\"] = df[\"Hepatomegaly\"].map({\"Y\": 1, \"N\": 0})\n",
    "df[\"Spiders\"] = df[\"Spiders\"].map({\"Y\": 1, \"N\": 0})\n",
    "df[\"Edema\"] = df[\"Edema\"].map({\n",
    "    \"No edema\": 0,\n",
    "    \"Edema no diuretics\": 0.5,\n",
    "    \"Edema despite diuretics\": 1\n",
    "})\n",
    "\n",
    "# === STEP 5: Drop Irrelevant/High-Missing Columns ===\n",
    "df.drop(columns=[\"ID\", \"Status\", \"Drug\", \"N_Days\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# === STEP 6: Convert all columns to numeric (in case any remain non-numeric) ===\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# === STEP 7: Fill Remaining NaNs with Column Means ===\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# === STEP 8: Split Features and Labels ===\n",
    "X = df.drop(\"Stage\", axis=1)\n",
    "y = df[\"Stage\"]-1\n",
    "\n",
    "# === STEP 9: Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === STEP 10: Scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === STEP 11: Train the Model ===\n",
    "model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === STEP 12: Evaluate the Model ===\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# === STEP 13: Save Model and Scaler ===\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\" Model and scaler saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c450038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs before splitting (whole df):\n",
      "Age                0\n",
      "Sex                0\n",
      "Ascites            0\n",
      "Hepatomegaly       0\n",
      "Spiders            0\n",
      "Edema            412\n",
      "Bilirubin          0\n",
      "Cholesterol        0\n",
      "Albumin            0\n",
      "Copper             0\n",
      "Alk_Phos           0\n",
      "SGOT               0\n",
      "Tryglicerides      0\n",
      "Platelets          0\n",
      "Prothrombin        0\n",
      "Stage              0\n",
      "dtype: int64\n",
      "Total NaNs: 412\n"
     ]
    }
   ],
   "source": [
    "# Check NaNs in full dataset\n",
    "print(\"NaNs before splitting (whole df):\")\n",
    "print(df.isnull().sum())\n",
    "print(\"Total NaNs:\", df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7402508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Edema values: ['y' 'n' 's']\n",
      "NaNs in df after mapping and fill: Age              0\n",
      "Sex              0\n",
      "Ascites          0\n",
      "Hepatomegaly     0\n",
      "Spiders          0\n",
      "Edema            0\n",
      "Bilirubin        0\n",
      "Cholesterol      0\n",
      "Albumin          0\n",
      "Copper           0\n",
      "Alk_Phos         0\n",
      "SGOT             0\n",
      "Tryglicerides    0\n",
      "Platelets        0\n",
      "Prothrombin      0\n",
      "Stage            0\n",
      "dtype: int64\n",
      "Total NaNs: 0\n",
      "NaNs in X_train: 0\n",
      "NaNs in X_test: 0\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29         6\n",
      "         1.0       0.21      0.22      0.22        18\n",
      "         2.0       0.52      0.61      0.56        28\n",
      "         3.0       0.57      0.55      0.56        31\n",
      "\n",
      "    accuracy                           0.47        83\n",
      "   macro avg       0.57      0.39      0.40        83\n",
      "weighted avg       0.50      0.47      0.46        83\n",
      "\n",
      " Model and Scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# === Liver Cirrhosis Stage Prediction: Model Training Script ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "# === STEP 1: Load and Clean Dataset ===\n",
    "df = pd.read_csv(\"cirrhosis.csv\")\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[\"Stage\"]).copy()\n",
    "\n",
    "# Encode categorical columns\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"M\": 1, \"F\": 0})\n",
    "df[\"Ascites\"] = df[\"Ascites\"].map({\"Y\": 1, \"N\": 0})\n",
    "df[\"Hepatomegaly\"] = df[\"Hepatomegaly\"].map({\"Y\": 1, \"N\": 0})\n",
    "df[\"Spiders\"] = df[\"Spiders\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# Fix and map 'Edema' values safely\n",
    "df[\"Edema\"] = df[\"Edema\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Print unique values for verification (optional)\n",
    "print(\"Unique Edema values:\", df[\"Edema\"].unique())\n",
    "\n",
    "# Map known values\n",
    "edema_mapping = {\n",
    "    \"no edema\": 0,\n",
    "    \"edema no diuretics\": 0.5,\n",
    "    \"edema despite diuretics\": 1,\n",
    "    \"0\": 0,\n",
    "    \"0.0\": 0,\n",
    "    \"0.5\": 0.5,\n",
    "    \"1\": 1,\n",
    "    \"1.0\": 1\n",
    "}\n",
    "# Final mapping for Edema values based on your actual data\n",
    "df[\"Edema\"] = df[\"Edema\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Map the actual values seen: 'y', 'n', 's'\n",
    "df[\"Edema\"] = df[\"Edema\"].map({\n",
    "    \"n\": 0,    # No edema\n",
    "    \"y\": 1,    # Edema present\n",
    "    \"s\": 0.5   # Some edema (assumed meaning)\n",
    "})\n",
    "\n",
    "\n",
    "# Drop unused or high-missing columns\n",
    "df.drop(columns=[\"ID\", \"Status\", \"Drug\", \"N_Days\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Convert all to numeric and fill any remaining NaNs\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Sanity check\n",
    "print(\"NaNs in df after mapping and fill:\", df.isnull().sum())\n",
    "print(\"Total NaNs:\", df.isnull().sum().sum())\n",
    "\n",
    "# === STEP 2: Split Features and Labels ===\n",
    "X = df.drop(\"Stage\", axis=1)\n",
    "y = df[\"Stage\"] - 1  # Shift labels to start from 0 for XGBoost\n",
    "\n",
    "# === STEP 3: Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Confirm NaNs in split\n",
    "print(\"NaNs in X_train:\", np.isnan(X_train).sum().sum())\n",
    "print(\"NaNs in X_test:\", np.isnan(X_test).sum().sum())\n",
    "\n",
    "# === STEP 4: Scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === STEP 5: Train the Model ===\n",
    "model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === STEP 6: Evaluate the Model ===\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# === STEP 7: Save the Model and Scaler ===\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\" Model and Scaler saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8678ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in df after mapping and fill: Age              0\n",
      "Sex              0\n",
      "Ascites          0\n",
      "Hepatomegaly     0\n",
      "Spiders          0\n",
      "Edema            0\n",
      "Bilirubin        0\n",
      "Cholesterol      0\n",
      "Albumin          0\n",
      "Copper           0\n",
      "Alk_Phos         0\n",
      "SGOT             0\n",
      "Tryglicerides    0\n",
      "Platelets        0\n",
      "Prothrombin      0\n",
      "Stage            0\n",
      "dtype: int64\n",
      "Total NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in df after mapping and fill:\", df.isnull().sum())\n",
    "print(\"Total NaNs:\", df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7e71f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage\n",
      "3.0    155\n",
      "4.0    144\n",
      "2.0     92\n",
      "1.0     21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Stage'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13a25a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anuup\\AppData\\Local\\Temp\\ipykernel_1260\\1817028091.py:7: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  print(\"Before SMOTE:\", np.bincount(y_train))\n",
      "C:\\Users\\anuup\\AppData\\Local\\Temp\\ipykernel_1260\\1817028091.py:8: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  print(\"After SMOTE: \", np.bincount(y_resampled))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [ 15  74 127 113]\n",
      "After SMOTE:  [127 127 127 127]\n",
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# After train-test split and scaling:\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "print(\"After SMOTE: \", np.bincount(y_resampled))\n",
    "\n",
    "# Train the model on balanced data\n",
    "model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "print(\"Model trained successfully!\")  # cleaner on GitHub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4bbe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f17bbd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model training complete.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_resampled, y_resampled)\n",
    "print(\" Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d26379b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.33      0.40         6\n",
      "         1.0       0.11      0.11      0.11        18\n",
      "         2.0       0.43      0.46      0.45        28\n",
      "         3.0       0.63      0.61      0.62        31\n",
      "\n",
      "    accuracy                           0.43        83\n",
      "   macro avg       0.42      0.38      0.39        83\n",
      "weighted avg       0.44      0.43      0.44        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
